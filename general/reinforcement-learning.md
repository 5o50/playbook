[https://github.com/karpathy/reinforcejs](https://github.com/karpathy/reinforcejs)

https://cs.stanford.edu/people/karpathy/reinforcejs/

[https://www.kdnuggets.com/2016/01/top-10-deep-learning-github.html](https://www.kdnuggets.com/2016/01/top-10-deep-learning-github.html)

[https://github.com/dennybritz/reinforcement-learning](https://github.com/dennybritz/reinforcement-learning)

https://www.npmjs.com/package/ml-js

**Reinforcement Learning / Q-Learning**

[https://github.com/dennybritz/reinforcement-learning](https://github.com/dennybritz/reinforcement-learning)

[http://incompleteideas.net/book/bookdraft2018jan1.pdf](http://incompleteideas.net/book/bookdraft2018jan1.pdf)

[http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html](http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html)

[http://www.readcube.com/articles/10.1038/nature14236](http://www.readcube.com/articles/10.1038/nature14236)

(MDP) Markov Decision Process

https://web.mst.edu/~gosavia/tutorial.pdf

SMDP

https://en.wikipedia.org/wiki/Reinforcement_learning

http://rll.berkeley.edu/deeprlcourse/

[https://gym.openai.com/envs/#classic_control](https://gym.openai.com/envs/#classic_control)

https://github.com/openai/gym

http://aikorea.org/awesome-rl/

https://sites.google.com/site/alexsusu/rl_and_mdp_pointers

[https://en.wikipedia.org/wiki/Q-learning](https://en.wikipedia.org/wiki/Q-learning)

[https://deepmind.com/blog/deep-reinforcement-learning/](https://deepmind.com/blog/deep-reinforcement-learning/)

[https://multiverseaccordingtoben.blogspot.com/2009/05/reinforcement-learning-some-limitations.html](https://multiverseaccordingtoben.blogspot.com/2009/05/reinforcement-learning-some-limitations.html)

[Reinforcement Learning Algorithms](https://github.com/dennybritz/reinforcement-learning)

[https://github.com/dennybritz/reinforcement-learning](https://github.com/dennybritz/reinforcement-learning)

**Value Function**

**Q Function**

Q(s,a) = r + y*max Q(s’, a’)

**Limits (**humans are not fully reward-driven**)**

[https://multiverseaccordingtoben.blogspot.com/2009/05/reinforcement-learning-some-limitations.html](https://multiverseaccordingtoben.blogspot.com/2009/05/reinforcement-learning-some-limitations.html)

**Reinforcement Learning Approaches**

The two big approaches to reinforcement learning are value based methods and policy gradient methods.

- Value based methods usually use the bellman equation to learn a value of action-value function and act greedily on it.
- Policy gradient methods update the parameters of a policy directly to favor reward. They can be improved using value based methods, resulting in .

    actor critic methods

- There are also  like the cross entropy method that works very well on simpler problems.

    non-parametric methods

**Bellman Equation (maximize their future reward) (averaging future reward over various future time-points)**

https://joshgreaves.com/reinforcement-learning/understanding-rl-the-bellman-equations/

[https://en.wikipedia.org/wiki/Bellman_equation](https://en.wikipedia.org/wiki/Bellman_equation)

**Stochastic Bellman Equation**

**Monte Carlo rollouts**

**Temporal Difference Learning**

**Deep Q Network**

[https://medium.com/@awjuliani/simple-reinforcement-learning-with-tensorflow-part-4-deep-q-networks-and-beyond-8438a3e2b8df](https://medium.com/@awjuliani/simple-reinforcement-learning-with-tensorflow-part-4-deep-q-networks-and-beyond-8438a3e2b8df)

**Asynchronous Actor-Critic Agents (A3C)**

[https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-8-asynchronous-actor-critic-agents-a3c-c88f72a5e9f2](https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-8-asynchronous-actor-critic-agents-a3c-c88f72a5e9f2)

[https://github.com/openai/universe-starter-agent](https://github.com/openai/universe-starter-agent)